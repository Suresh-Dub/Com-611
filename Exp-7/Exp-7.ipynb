{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a05074",
   "metadata": {},
   "source": [
    "# Implement the web scraping on Amazon website or any shopping site by importing the requests and the beautiful Soup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ffb20d",
   "metadata": {},
   "source": [
    "Two Python libraries are used : BeautifulSoup and requests.\n",
    "BeautifulSoup is part of the bs4 module\n",
    "requests is a library used for sending HTTP requests in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff3936",
   "metadata": {},
   "source": [
    "1.Import the necessary libraries:\n",
    "    BeautifulSoup from the bs4 module for parsing HTML content.\n",
    "    requests for sending HTTP requests\n",
    "2.Define the function get_title(soup) to extract the product price.\n",
    "    Similar to the get_title functon, find the element using soup.find() with the specified attributes.\n",
    "    Check if the element exists (price is Not None), and if so, retrieve the text value using get_text(strip=true).\n",
    "    Handle the AttributesError and set price_String to an empty string if the element is not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e3a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "# Function to extract Product Title\n",
    "def get_title(soup):\n",
    "    try:\n",
    "        title= soup.find(\"span\", attrs={\"id\":\"productTitle\"})\n",
    "        title_string=title.get_text(strip=True)\n",
    "    except AttributeError:\n",
    "        title_string=\"\"\n",
    "    return title_string\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "    try:\n",
    "        price=soup.find(\"span\",attrs={\"class\":\"a-offscreen\"})\n",
    "        if price is not None:\n",
    "            price_string=price.get_text(strip=True)\n",
    "        else:\n",
    "            price_string=\"\"\n",
    "    except AttributeError:\n",
    "        price_string=\"\"\n",
    "    return price_string\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "    try:\n",
    "        rating=soup.find(\"span\",attrs={\"class\":\"a-icon-alt\"})\n",
    "        if rating is not None:\n",
    "            rating_string=rating.get_text(strip=True)\n",
    "        else:\n",
    "            rating_string=\"\"\n",
    "    except AttributeError:\n",
    "        rating_string=\"\"\n",
    "    return rating_string\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count=soup.find(\"span\",attrs={\"id\":\"acrCustomerReviewText\"})\n",
    "        if review_count is not None:\n",
    "            review_count_string=review_count.get_text(strip=True)\n",
    "        else:\n",
    "            review_count_string=\"\"\n",
    "    except AttributeError:\n",
    "        review_count_string=\"\"\n",
    "    return review_count_string\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available=soup.find(\"div\",attrs={\"id\":\"availability\"})\n",
    "        if available is not None:\n",
    "            availability_string=available.get_text(strip=True)\n",
    "        else:\n",
    "            availability_string=\"\"\n",
    "    except AttributeError:\n",
    "        availability_string=\"\"\n",
    "    return availability_string\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #Headers for request\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36\",\n",
    "        \"Accept-Language\": \"en-us, en;q=0.5\"\n",
    "    }\n",
    "    \n",
    "    # The webpage url \n",
    "    url = \"https://www.amazon.in/ASUS-Geforce-Graphics-Displayport-pci_e_x16/dp/B0BSVMLVTD/ref=sr_1_3?dib=eyJ2IjoiMSJ9.neLExJIE0KTW9-_VvwRN2SuBKY8-q9hgQ7wNQ1sqGj4SnD6r_ilZgPB0r0hCJFkaGCZzQXpDJlG08As1UXXZtiqWWYhnJ1NF13yJkMyWAAFRW5R4n6PHHsy7GF_zoWfhlC0XcRzMJKO8MWw9ywZP_UoWGuhFUV0ec7GILHjnMTYe1xjM8VtrrjYGzWKpN_SN2Xd2nfFQBLxFNpxBKXKDvJRpA3uIX-F3QRSFXelKqd70Xl7CJFvcl-ox2zTcGWZ9ArYpjANmNJm2WFIcXT3Cwszy0R-j7krckL9SJ6PO168.7eyWHauCdQYgfs2nzR2zOkVF7Mjee4FFu3aRHGZQP98&dib_tag=se&keywords=RTX+4090&qid=1714549420&s=computers&sr=1-3\"\n",
    "\n",
    "\n",
    "    # HTTP Request\n",
    "    webpage = requests.get(url, headers=headers)\n",
    "\n",
    "    # Soup object containing all data\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Function calls to display all necessary product information\n",
    "    print(\"Product Title =\", get_title(soup))\n",
    "    print(\"Product Price =\", get_price(soup))\n",
    "    print(\"Product Rating =\", get_rating(soup))\n",
    "    print(\"Number of Product Review =\", get_review_count(soup))\n",
    "    print(\"Availability =\", get_availability(soup))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
